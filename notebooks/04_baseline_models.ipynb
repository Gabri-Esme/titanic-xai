{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bfaaf56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Fare   Age  Sex_male  Pclass  Title_Mr  Title_Master  SibSp  \\\n",
      "0   7.2500  22.0      True       3      True         False      1   \n",
      "1  71.2833  38.0     False       1     False         False      1   \n",
      "2   7.9250  26.0     False       3     False         False      0   \n",
      "3  53.1000  35.0     False       1     False         False      1   \n",
      "4   8.0500  35.0      True       3      True         False      0   \n",
      "\n",
      "   CabinLetter_U  Survived  \n",
      "0           True         0  \n",
      "1          False         1  \n",
      "2           True         1  \n",
      "3          False         1  \n",
      "4           True         0  \n"
     ]
    }
   ],
   "source": [
    "%store -r df\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b724a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8212290502793296\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85       105\n",
      "           1       0.79      0.77      0.78        74\n",
      "\n",
      "    accuracy                           0.82       179\n",
      "   macro avg       0.82      0.81      0.81       179\n",
      "weighted avg       0.82      0.82      0.82       179\n",
      "\n",
      "[[90 15]\n",
      " [17 57]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Test - Train Split\n",
    "X = df.drop(columns=['Survived']) # All features\n",
    "y = df['Survived'] # Target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model Training\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Model Evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7da994cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.8101\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84       105\n",
      "           1       0.78      0.76      0.77        74\n",
      "\n",
      "    accuracy                           0.81       179\n",
      "   macro avg       0.80      0.80      0.80       179\n",
      "weighted avg       0.81      0.81      0.81       179\n",
      "\n",
      "[[89 16]\n",
      " [18 56]]\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression with L1 Regularization\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Test - Train Split\n",
    "X = df.drop(columns=['Survived']) # All features\n",
    "y = df['Survived'] # Target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression with L1 penalty\n",
    "lr = LogisticRegression(penalty='l1', solver='liblinear', random_state=42)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "# Model Evaluation\n",
    "acc_lr = accuracy_score(y_test, y_pred_lr)\n",
    "print(f\"Logistic Regression Accuracy: {acc_lr:.4f}\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "print(confusion_matrix(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "619c92ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoosting Accuracy: 0.8380\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87       105\n",
      "           1       0.84      0.76      0.79        74\n",
      "\n",
      "    accuracy                           0.84       179\n",
      "   macro avg       0.84      0.83      0.83       179\n",
      "weighted avg       0.84      0.84      0.84       179\n",
      "\n",
      "[[94 11]\n",
      " [18 56]]\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Test - Train Split\n",
    "X = df.drop(columns=['Survived']) # All features\n",
    "y = df['Survived'] # Target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_gb = gb.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "print(f\"GradientBoosting Accuracy: {accuracy_score(y_test, y_pred_gb):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_gb))\n",
    "print(confusion_matrix(y_test, y_pred_gb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f189db20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gb.joblib']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "dump(gb, 'gb.joblib')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
